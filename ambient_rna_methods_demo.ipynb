{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambient RNA Removal Methods Comparison\n",
    "## Quick Demo: DecontX, FastCAR, and CellBender\n",
    "\n",
    "**Meeting prep for geometric data analysis research**\n",
    "\n",
    "Methods covered:\n",
    "- ‚úÖ SoupX (already done by partner)\n",
    "- üÜï DecontX (cluster-based contamination)\n",
    "- üÜï FastCAR (sample-specific, DGE-optimized)\n",
    "- üìã CellBender (reference implementation)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting parameters\n",
    "sc.settings.verbosity = 1\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white', frameon=False)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"Scanpy version: {sc.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data with Known Ground Truth\n",
    "\n",
    "This is **critical** for validation - we know the true signal and true contamination!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_contaminated(\n",
    "    n_cells=1000,\n",
    "    n_genes=2000,\n",
    "    n_cell_types=5,\n",
    "    contamination_rate=0.15,\n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic scRNA-seq data with known ambient RNA contamination.\n",
    "    \n",
    "    Returns AnnData with:\n",
    "    - X: Observed counts (signal + noise)\n",
    "    - uns['true_signal']: Ground truth signal\n",
    "    - uns['ambient_profile']: True ambient profile\n",
    "    - obs['true_contamination']: True contamination fraction\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    print(f\"üß¨ Generating synthetic data...\")\n",
    "    print(f\"   Cells: {n_cells}, Genes: {n_genes}, Cell types: {n_cell_types}\")\n",
    "    print(f\"   Contamination rate: {contamination_rate:.1%}\")\n",
    "    \n",
    "    # Assign cell types\n",
    "    cell_types = np.random.choice(n_cell_types, n_cells)\n",
    "    \n",
    "    # Generate distinct cell type expression profiles\n",
    "    # Using Gamma distribution for realistic gene expression\n",
    "    profiles = np.zeros((n_cell_types, n_genes))\n",
    "    for ct in range(n_cell_types):\n",
    "        # Each cell type has marker genes\n",
    "        marker_genes = slice(ct * (n_genes // n_cell_types), (ct + 1) * (n_genes // n_cell_types))\n",
    "        profiles[ct, marker_genes] = np.random.gamma(5, 2, n_genes // n_cell_types)  # High expression\n",
    "        profiles[ct, :] += np.random.gamma(1, 0.5, n_genes)  # Background expression\n",
    "    \n",
    "    # True biological signal for each cell\n",
    "    S_true = profiles[cell_types]\n",
    "    \n",
    "    # Add cell-to-cell variability\n",
    "    cell_size_factors = np.random.lognormal(0, 0.3, n_cells)\n",
    "    S_true = S_true * cell_size_factors[:, np.newaxis]\n",
    "    \n",
    "    # Ambient profile (mixture from all cell types, weighted by abundance)\n",
    "    cell_type_weights = np.bincount(cell_types, minlength=n_cell_types) / n_cells\n",
    "    ambient = (profiles.T @ cell_type_weights)\n",
    "    \n",
    "    # Add ambient contamination\n",
    "    # Variable contamination per cell\n",
    "    contamination_fractions = np.random.beta(2, 10, n_cells) * contamination_rate * 2\n",
    "    \n",
    "    # Observed counts = True signal + Ambient noise\n",
    "    observed = np.zeros_like(S_true)\n",
    "    for i in range(n_cells):\n",
    "        cell_total = S_true[i].sum()\n",
    "        true_counts = np.random.poisson(S_true[i])\n",
    "        ambient_counts = np.random.poisson(contamination_fractions[i] * cell_total * ambient / ambient.sum())\n",
    "        observed[i] = true_counts + ambient_counts\n",
    "    \n",
    "    # Also generate empty droplets for ambient estimation\n",
    "    n_empty = 200\n",
    "    empty_counts = np.random.poisson(\n",
    "        np.random.uniform(10, 100, (n_empty, 1)) * ambient / ambient.sum(),\n",
    "        size=(n_empty, n_genes)\n",
    "    )\n",
    "    \n",
    "    # Combine cells and empty droplets\n",
    "    all_counts = np.vstack([observed, empty_counts])\n",
    "    \n",
    "    # Create AnnData object\n",
    "    adata = sc.AnnData(X=csr_matrix(all_counts.astype(int)))\n",
    "    adata.obs['cell_type'] = [f'Type_{ct}' for ct in cell_types] + ['Empty'] * n_empty\n",
    "    adata.obs['is_cell'] = [True] * n_cells + [False] * n_empty\n",
    "    adata.obs['true_contamination'] = list(contamination_fractions) + [1.0] * n_empty\n",
    "    adata.var_names = [f'Gene_{i}' for i in range(n_genes)]\n",
    "    \n",
    "    # Store ground truth\n",
    "    adata.uns['true_signal'] = S_true\n",
    "    adata.uns['ambient_profile'] = ambient\n",
    "    adata.uns['true_profiles'] = profiles\n",
    "    \n",
    "    print(f\"‚úÖ Generated {n_cells} cells + {n_empty} empty droplets\")\n",
    "    print(f\"   Mean contamination: {contamination_fractions.mean():.1%}\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "# Generate synthetic dataset\n",
    "adata_synthetic = generate_synthetic_contaminated(\n",
    "    n_cells=1000,\n",
    "    n_genes=2000,\n",
    "    n_cell_types=5,\n",
    "    contamination_rate=0.15\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data shape: {adata_synthetic.shape}\")\n",
    "print(f\"   Cell types: {adata_synthetic.obs['cell_type'].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Real Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PBMC3K (preprocessed)\n",
    "print(\"üì• Loading PBMC3K dataset...\")\n",
    "adata_pbmc = sc.datasets.pbmc3k_processed()\n",
    "print(f\"   Shape: {adata_pbmc.shape}\")\n",
    "print(f\"   Cell types: {adata_pbmc.obs['louvain'].nunique()}\")\n",
    "\n",
    "# For demonstration, we'll work with raw counts\n",
    "# In practice, you'd load the raw matrix before filtering\n",
    "print(\"\\n‚ö†Ô∏è  Note: PBMC3K is pre-filtered. For real analysis, use raw counts!\")\n",
    "\n",
    "# Optional: Load bone marrow data\n",
    "try:\n",
    "    print(\"\\nüì• Loading bone marrow (Paul15) dataset...\")\n",
    "    adata_bm = sc.datasets.paul15()\n",
    "    print(f\"   Shape: {adata_bm.shape}\")\n",
    "    print(f\"   Cell types: {adata_bm.obs['paul15_clusters'].nunique()}\")\n",
    "except:\n",
    "    print(\"   ‚ö†Ô∏è  Paul15 dataset not available, skipping\")\n",
    "    adata_bm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method Implementation: DecontX\n",
    "\n",
    "**Key idea**: Contamination comes from OTHER cell populations, weighted by cluster size.\n",
    "\n",
    "Mathematical model:\n",
    "$$Y_n \\sim \\text{Multinomial}(N_n, \\theta_n)$$\n",
    "$$\\theta_n = (1 - \\phi_n)\\pi_{c(n)} + \\phi_n \\eta_n$$\n",
    "\n",
    "where $\\eta_n = \\sum_{k \\neq c(n)} w_k \\pi_k$ (weighted mixture from other clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontX_simple(adata, cluster_key='cell_type', max_iter=50, convergence_threshold=1e-4):\n",
    "    \"\"\"\n",
    "    Simplified DecontX implementation.\n",
    "    \n",
    "    Based on: Yang et al. (2020) Genome Biology 21:57\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Input data with raw counts\n",
    "    cluster_key : str\n",
    "        Key in adata.obs for cluster labels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    adata_corrected : AnnData\n",
    "        Corrected counts with contamination estimates\n",
    "    \"\"\"\n",
    "    print(\"üî¨ Running DecontX...\")\n",
    "    \n",
    "    # Get counts matrix\n",
    "    if issparse(adata.X):\n",
    "        X = adata.X.toarray()\n",
    "    else:\n",
    "        X = adata.X.copy()\n",
    "    \n",
    "    # Only use cells (not empty droplets)\n",
    "    if 'is_cell' in adata.obs.columns:\n",
    "        cell_mask = adata.obs['is_cell'].values\n",
    "        X_cells = X[cell_mask]\n",
    "        clusters = adata.obs.loc[cell_mask, cluster_key].values\n",
    "    else:\n",
    "        X_cells = X\n",
    "        clusters = adata.obs[cluster_key].values\n",
    "        cell_mask = np.ones(adata.n_obs, dtype=bool)\n",
    "    \n",
    "    n_cells, n_genes = X_cells.shape\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    n_clusters = len(unique_clusters)\n",
    "    \n",
    "    print(f\"   Cells: {n_cells}, Genes: {n_genes}, Clusters: {n_clusters}\")\n",
    "    \n",
    "    # Initialize cluster expression profiles\n",
    "    cluster_profiles = np.zeros((n_clusters, n_genes))\n",
    "    cluster_sizes = np.zeros(n_clusters)\n",
    "    \n",
    "    for i, cluster in enumerate(unique_clusters):\n",
    "        mask = clusters == cluster\n",
    "        cluster_sizes[i] = mask.sum()\n",
    "        cluster_profiles[i] = X_cells[mask].sum(axis=0)\n",
    "        cluster_profiles[i] /= cluster_profiles[i].sum() + 1e-10  # Normalize\n",
    "    \n",
    "    # Initialize contamination fractions\n",
    "    phi = np.random.uniform(0.01, 0.2, n_cells)\n",
    "    \n",
    "    # EM algorithm\n",
    "    for iteration in range(max_iter):\n",
    "        phi_old = phi.copy()\n",
    "        \n",
    "        # E-step: Estimate contamination for each cell\n",
    "        for i in range(n_cells):\n",
    "            cell_cluster_idx = np.where(unique_clusters == clusters[i])[0][0]\n",
    "            \n",
    "            # Native profile\n",
    "            native = cluster_profiles[cell_cluster_idx]\n",
    "            \n",
    "            # Contamination profile (weighted by OTHER cluster sizes)\n",
    "            other_mask = np.arange(n_clusters) != cell_cluster_idx\n",
    "            weights = cluster_sizes[other_mask] / cluster_sizes[other_mask].sum()\n",
    "            contamination = (cluster_profiles[other_mask].T @ weights)\n",
    "            \n",
    "            # Cell counts\n",
    "            y = X_cells[i]\n",
    "            total = y.sum()\n",
    "            \n",
    "            if total == 0:\n",
    "                continue\n",
    "            \n",
    "            # Estimate phi using simple moment matching\n",
    "            # phi = correlation with contamination profile\n",
    "            obs_freq = y / (total + 1e-10)\n",
    "            \n",
    "            # Score how well native vs contamination explains data\n",
    "            native_score = np.corrcoef(obs_freq, native)[0, 1] if native.sum() > 0 else 0\n",
    "            contam_score = np.corrcoef(obs_freq, contamination)[0, 1] if contamination.sum() > 0 else 0\n",
    "            \n",
    "            # Estimate contamination fraction\n",
    "            if native_score + contam_score > 0:\n",
    "                phi[i] = max(0, min(0.5, contam_score / (native_score + contam_score + 1e-10)))\n",
    "            else:\n",
    "                phi[i] = 0.1\n",
    "        \n",
    "        # M-step: Update cluster profiles\n",
    "        for i, cluster in enumerate(unique_clusters):\n",
    "            mask = clusters == cluster\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            # Weight by (1 - phi) to down-weight contaminated cells\n",
    "            weights = (1 - phi[mask])[:, np.newaxis]\n",
    "            cluster_profiles[i] = (X_cells[mask] * weights).sum(axis=0)\n",
    "            cluster_profiles[i] /= cluster_profiles[i].sum() + 1e-10\n",
    "        \n",
    "        # Check convergence\n",
    "        change = np.abs(phi - phi_old).mean()\n",
    "        if change < convergence_threshold:\n",
    "            print(f\"   ‚úÖ Converged at iteration {iteration + 1}\")\n",
    "            break\n",
    "    \n",
    "    # Correct counts\n",
    "    X_corrected = X.copy()\n",
    "    cell_idx = 0\n",
    "    \n",
    "    for i in range(adata.n_obs):\n",
    "        if not cell_mask[i]:\n",
    "            continue\n",
    "        \n",
    "        cluster_idx = np.where(unique_clusters == clusters[cell_idx])[0][0]\n",
    "        other_mask = np.arange(n_clusters) != cluster_idx\n",
    "        weights = cluster_sizes[other_mask] / cluster_sizes[other_mask].sum()\n",
    "        contamination = (cluster_profiles[other_mask].T @ weights)\n",
    "        \n",
    "        # Subtract contamination\n",
    "        total = X[i].sum()\n",
    "        correction = phi[cell_idx] * total * contamination\n",
    "        X_corrected[i] = np.maximum(X[i] - correction, 0)\n",
    "        \n",
    "        cell_idx += 1\n",
    "    \n",
    "    # Create output\n",
    "    adata_corrected = adata.copy()\n",
    "    adata_corrected.X = csr_matrix(X_corrected)\n",
    "    adata_corrected.obs['decontX_contamination'] = 0.0\n",
    "    adata_corrected.obs.loc[cell_mask, 'decontX_contamination'] = phi\n",
    "    \n",
    "    print(f\"   Mean contamination: {phi.mean():.1%}\")\n",
    "    print(f\"   Range: {phi.min():.1%} - {phi.max():.1%}\")\n",
    "    \n",
    "    return adata_corrected\n",
    "\n",
    "# Test on synthetic data\n",
    "adata_decontx = decontX_simple(adata_synthetic, cluster_key='cell_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method Implementation: FastCAR\n",
    "\n",
    "**Key idea**: Sample-specific ambient correction optimized for differential expression.\n",
    "\n",
    "Mathematical model:\n",
    "$$S^{(s)}_{ng} = \\max(0, Y^{(s)}_{ng} - \\rho^{(s)}_n \\cdot A^{(s)}_g)$$\n",
    "\n",
    "Reference: Muskovic & Powell (2023) BMC Genomics 24:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastCAR_correction(adata, empty_droplet_cutoff=100, marker_genes=None):\n",
    "    \"\"\"\n",
    "    FastCAR: Sample-specific ambient RNA correction.\n",
    "    \n",
    "    Based on: Muskovic & Powell (2023) BMC Genomics 24:1\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        Input data with raw counts\n",
    "    empty_droplet_cutoff : int\n",
    "        UMI threshold to identify empty droplets\n",
    "    marker_genes : list, optional\n",
    "        Known non-expressed genes for contamination estimation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    adata_corrected : AnnData\n",
    "        Corrected counts with contamination estimates\n",
    "    \"\"\"\n",
    "    print(\"üöó Running FastCAR...\")\n",
    "    \n",
    "    # Get counts matrix\n",
    "    if issparse(adata.X):\n",
    "        X = adata.X.toarray()\n",
    "    else:\n",
    "        X = adata.X.copy()\n",
    "    \n",
    "    n_cells, n_genes = X.shape\n",
    "    \n",
    "    # Identify empty droplets\n",
    "    total_counts = X.sum(axis=1)\n",
    "    \n",
    "    if 'is_cell' in adata.obs.columns:\n",
    "        empty_mask = ~adata.obs['is_cell'].values\n",
    "    else:\n",
    "        empty_mask = total_counts < empty_droplet_cutoff\n",
    "    \n",
    "    print(f\"   Identified {empty_mask.sum()} empty droplets\")\n",
    "    \n",
    "    # Estimate ambient profile from empty droplets\n",
    "    if empty_mask.sum() > 0:\n",
    "        ambient_profile = X[empty_mask].sum(axis=0)\n",
    "        ambient_profile = ambient_profile / (ambient_profile.sum() + 1e-10)\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No empty droplets found, using lowest 10% of cells\")\n",
    "        low_umi_mask = total_counts < np.percentile(total_counts, 10)\n",
    "        ambient_profile = X[low_umi_mask].sum(axis=0)\n",
    "        ambient_profile = ambient_profile / (ambient_profile.sum() + 1e-10)\n",
    "    \n",
    "    # Estimate contamination fraction per cell\n",
    "    contamination_fractions = np.zeros(n_cells)\n",
    "    corrected_counts = X.copy()\n",
    "    cell_mask = ~empty_mask\n",
    "    \n",
    "    for i in range(n_cells):\n",
    "        if empty_mask[i]:\n",
    "            contamination_fractions[i] = 1.0\n",
    "            continue\n",
    "        \n",
    "        cell_counts = X[i]\n",
    "        total = cell_counts.sum()\n",
    "        \n",
    "        if total == 0:\n",
    "            continue\n",
    "        \n",
    "        # Method 1: Use correlation with ambient profile\n",
    "        cell_freq = cell_counts / (total + 1e-10)\n",
    "        \n",
    "        # Genes with high ambient but low cell expression = contamination markers\n",
    "        if marker_genes is not None:\n",
    "            # Use provided marker genes\n",
    "            marker_idx = [i for i, g in enumerate(adata.var_names) if g in marker_genes]\n",
    "        else:\n",
    "            # Identify high-ambient genes\n",
    "            high_ambient = ambient_profile > np.percentile(ambient_profile, 90)\n",
    "            low_cell = cell_freq < np.percentile(cell_freq, 10)\n",
    "            marker_idx = np.where(high_ambient & low_cell)[0]\n",
    "        \n",
    "        if len(marker_idx) > 10:\n",
    "            # Estimate rho from marker genes\n",
    "            observed_marker = cell_counts[marker_idx].sum()\n",
    "            expected_marker = total * ambient_profile[marker_idx].sum()\n",
    "            rho = observed_marker / (expected_marker + 1e-10)\n",
    "            rho = max(0, min(rho, 0.5))  # Bound between 0-50%\n",
    "        else:\n",
    "            # Fallback: correlation-based estimate\n",
    "            corr = np.corrcoef(cell_freq, ambient_profile)[0, 1]\n",
    "            rho = max(0, min(corr, 0.5))\n",
    "        \n",
    "        contamination_fractions[i] = rho\n",
    "        \n",
    "        # Correct counts: S = max(0, Y - rho * A * total)\n",
    "        correction = rho * total * ambient_profile\n",
    "        corrected_counts[i] = np.maximum(cell_counts - correction, 0)\n",
    "    \n",
    "    # Create output\n",
    "    adata_corrected = adata.copy()\n",
    "    adata_corrected.X = csr_matrix(corrected_counts)\n",
    "    adata_corrected.obs['fastcar_contamination'] = contamination_fractions\n",
    "    adata_corrected.uns['ambient_profile'] = ambient_profile\n",
    "    \n",
    "    valid_cells = cell_mask\n",
    "    print(f\"   Mean contamination (cells only): {contamination_fractions[valid_cells].mean():.1%}\")\n",
    "    print(f\"   Range: {contamination_fractions[valid_cells].min():.1%} - {contamination_fractions[valid_cells].max():.1%}\")\n",
    "    \n",
    "    return adata_corrected\n",
    "\n",
    "# Test on synthetic data\n",
    "adata_fastcar = fastCAR_correction(adata_synthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Methods on Synthetic Data\n",
    "\n",
    "**This is the gold standard** - we know the true signal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_correction(adata_corrected, adata_original, method_name):\n",
    "    \"\"\"\n",
    "    Evaluate correction quality against ground truth.\n",
    "    \"\"\"\n",
    "    # Only evaluate on cells (not empty droplets)\n",
    "    cell_mask = adata_original.obs['is_cell'].values\n",
    "    \n",
    "    # Get matrices\n",
    "    if issparse(adata_corrected.X):\n",
    "        corrected = adata_corrected.X.toarray()[cell_mask]\n",
    "    else:\n",
    "        corrected = adata_corrected.X[cell_mask]\n",
    "    \n",
    "    if issparse(adata_original.X):\n",
    "        observed = adata_original.X.toarray()[cell_mask]\n",
    "    else:\n",
    "        observed = adata_original.X[cell_mask]\n",
    "    \n",
    "    true_signal = adata_original.uns['true_signal']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    # 1. RMSE (lower is better)\n",
    "    rmse_corrected = np.sqrt(((corrected - true_signal) ** 2).mean())\n",
    "    rmse_observed = np.sqrt(((observed - true_signal) ** 2).mean())\n",
    "    \n",
    "    # 2. Pearson correlation (higher is better)\n",
    "    corr_corrected = pearsonr(corrected.flatten(), true_signal.flatten())[0]\n",
    "    corr_observed = pearsonr(observed.flatten(), true_signal.flatten())[0]\n",
    "    \n",
    "    # 3. Contamination estimation accuracy\n",
    "    true_contam = adata_original.obs.loc[cell_mask, 'true_contamination'].values\n",
    "    \n",
    "    if 'decontX_contamination' in adata_corrected.obs.columns:\n",
    "        est_contam = adata_corrected.obs.loc[cell_mask, 'decontX_contamination'].values\n",
    "    elif 'fastcar_contamination' in adata_corrected.obs.columns:\n",
    "        est_contam = adata_corrected.obs.loc[cell_mask, 'fastcar_contamination'].values\n",
    "    else:\n",
    "        est_contam = None\n",
    "    \n",
    "    contam_corr = pearsonr(true_contam, est_contam)[0] if est_contam is not None else None\n",
    "    \n",
    "    results = {\n",
    "        'Method': method_name,\n",
    "        'RMSE (Corrected)': rmse_corrected,\n",
    "        'RMSE (Observed)': rmse_observed,\n",
    "        'RMSE Improvement': (rmse_observed - rmse_corrected) / rmse_observed * 100,\n",
    "        'Correlation (Corrected)': corr_corrected,\n",
    "        'Correlation (Observed)': corr_observed,\n",
    "        'Contamination Est. Corr': contam_corr\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate both methods\n",
    "print(\"üìä Evaluating methods on synthetic data...\\n\")\n",
    "\n",
    "results_decontx = evaluate_correction(adata_decontx, adata_synthetic, 'DecontX')\n",
    "results_fastcar = evaluate_correction(adata_fastcar, adata_synthetic, 'FastCAR')\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame([results_decontx, results_fastcar])\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n‚úÖ Higher correlation and lower RMSE = better performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Only plot cells (not empty droplets)\n",
    "cell_mask = adata_synthetic.obs['is_cell'].values\n",
    "\n",
    "# Row 1: PCA visualizations\n",
    "datasets = [\n",
    "    (adata_synthetic[cell_mask].copy(), 'Raw (with contamination)'),\n",
    "    (adata_decontx[cell_mask].copy(), 'DecontX corrected'),\n",
    "    (adata_fastcar[cell_mask].copy(), 'FastCAR corrected')\n",
    "]\n",
    "\n",
    "for idx, (adata_plot, title) in enumerate(datasets):\n",
    "    sc.pp.normalize_total(adata_plot, target_sum=1e4)\n",
    "    sc.pp.log1p(adata_plot)\n",
    "    sc.pp.pca(adata_plot, n_comps=20)\n",
    "    \n",
    "    ax = axes[0, idx]\n",
    "    sc.pl.pca(adata_plot, color='cell_type', ax=ax, show=False, title=title)\n",
    "\n",
    "# Row 2: Contamination estimates vs truth\n",
    "true_contam = adata_synthetic.obs.loc[cell_mask, 'true_contamination'].values\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.hist(true_contam, bins=30, alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('True Contamination Fraction')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Ground Truth Contamination')\n",
    "ax.axvline(true_contam.mean(), color='red', linestyle='--', label=f'Mean: {true_contam.mean():.1%}')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1, 1]\n",
    "est_contam_decontx = adata_decontx.obs.loc[cell_mask, 'decontX_contamination'].values\n",
    "ax.scatter(true_contam, est_contam_decontx, alpha=0.5, s=20)\n",
    "ax.plot([0, 0.5], [0, 0.5], 'r--', label='Perfect estimate')\n",
    "ax.set_xlabel('True Contamination')\n",
    "ax.set_ylabel('DecontX Estimate')\n",
    "ax.set_title(f'DecontX (r={pearsonr(true_contam, est_contam_decontx)[0]:.3f})')\n",
    "ax.legend()\n",
    "ax.set_xlim([0, 0.5])\n",
    "ax.set_ylim([0, 0.5])\n",
    "\n",
    "ax = axes[1, 2]\n",
    "est_contam_fastcar = adata_fastcar.obs.loc[cell_mask, 'fastcar_contamination'].values\n",
    "ax.scatter(true_contam, est_contam_fastcar, alpha=0.5, s=20, color='orange')\n",
    "ax.plot([0, 0.5], [0, 0.5], 'r--', label='Perfect estimate')\n",
    "ax.set_xlabel('True Contamination')\n",
    "ax.set_ylabel('FastCAR Estimate')\n",
    "ax.set_title(f'FastCAR (r={pearsonr(true_contam, est_contam_fastcar)[0]:.3f})')\n",
    "ax.legend()\n",
    "ax.set_xlim([0, 0.5])\n",
    "ax.set_ylim([0, 0.5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/method_comparison_synthetic.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nüíæ Saved: method_comparison_synthetic.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Signal Recovery Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "cell_mask = adata_synthetic.obs['is_cell'].values\n",
    "\n",
    "# Get data\n",
    "true_signal = adata_synthetic.uns['true_signal']\n",
    "observed = adata_synthetic.X.toarray()[cell_mask] if issparse(adata_synthetic.X) else adata_synthetic.X[cell_mask]\n",
    "decontx = adata_decontx.X.toarray()[cell_mask] if issparse(adata_decontx.X) else adata_decontx.X[cell_mask]\n",
    "fastcar = adata_fastcar.X.toarray()[cell_mask] if issparse(adata_fastcar.X) else adata_fastcar.X[cell_mask]\n",
    "\n",
    "# Subsample for visualization\n",
    "n_points = min(10000, true_signal.size)\n",
    "idx = np.random.choice(true_signal.size, n_points, replace=False)\n",
    "\n",
    "datasets = [\n",
    "    (observed.flatten()[idx], 'Raw Observed'),\n",
    "    (decontx.flatten()[idx], 'DecontX'),\n",
    "    (fastcar.flatten()[idx], 'FastCAR')\n",
    "]\n",
    "\n",
    "for i, (data, name) in enumerate(datasets):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    true_sub = true_signal.flatten()[idx]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(true_sub, data, alpha=0.1, s=1)\n",
    "    ax.plot([0, true_sub.max()], [0, true_sub.max()], 'r--', linewidth=2, label='Perfect recovery')\n",
    "    \n",
    "    corr = pearsonr(true_sub, data)[0]\n",
    "    ax.set_xlabel('True Signal')\n",
    "    ax.set_ylabel(f'{name} Counts')\n",
    "    ax.set_title(f'{name}\\n(r = {corr:.3f})')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0, np.percentile(true_sub, 99)])\n",
    "    ax.set_ylim([0, np.percentile(data, 99)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/signal_recovery.png', dpi=300, bbox_inches='tight')\n",
    "print(\"üíæ Saved: signal_recovery.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Apply to Real Data (PBMC3K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Applying methods to PBMC3K...\\n\")\n",
    "\n",
    "# Note: PBMC3K is already filtered, so this is for demonstration\n",
    "# In practice, you'd load raw counts before any filtering\n",
    "\n",
    "# Apply DecontX\n",
    "adata_pbmc_decontx = decontX_simple(adata_pbmc.copy(), cluster_key='louvain')\n",
    "print()\n",
    "\n",
    "# Apply FastCAR\n",
    "adata_pbmc_fastcar = fastCAR_correction(adata_pbmc.copy())\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Methods applied to PBMC3K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PBMC results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets_pbmc = [\n",
    "    (adata_pbmc, 'Original PBMC3K'),\n",
    "    (adata_pbmc_decontx, 'DecontX corrected'),\n",
    "    (adata_pbmc_fastcar, 'FastCAR corrected')\n",
    "]\n",
    "\n",
    "for idx, (adata_plot, title) in enumerate(datasets_pbmc):\n",
    "    ax = axes[idx]\n",
    "    sc.pl.umap(adata_plot, color='louvain', ax=ax, show=False, title=title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/pbmc_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"üíæ Saved: pbmc_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Table for Meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "summary_data = {\n",
    "    'Method': ['SoupX', 'DecontX', 'FastCAR', 'CellBender'],\n",
    "    'Status': ['‚úÖ Done (Partner)', '‚úÖ Implemented', '‚úÖ Implemented', 'üìã Reference only'],\n",
    "    'Speed': ['Fast', 'Medium', 'Very Fast', 'Slow (GPU)'],\n",
    "    'Approach': [\n",
    "        'Gene-specific propensity',\n",
    "        'Cluster-weighted mixture',\n",
    "        'Per-sample DGE-optimized',\n",
    "        'Deep generative model'\n",
    "    ],\n",
    "    'Best For': [\n",
    "        'Filtered data',\n",
    "        'Cluster-based analysis',\n",
    "        'Disease vs. control',\n",
    "        'Heavy contamination'\n",
    "    ],\n",
    "    'Key Innovation': [\n",
    "        'MT/ribo genes contaminate more',\n",
    "        'Contamination from OTHER clusters',\n",
    "        'Sample-specific correction',\n",
    "        'Neural net learns manifold'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã METHOD SUMMARY FOR MEETING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Performance on synthetic data\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä PERFORMANCE ON SYNTHETIC DATA (Ground Truth Known)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "summary_df.to_csv('/home/claude/method_summary.csv', index=False)\n",
    "comparison_df.to_csv('/home/claude/performance_comparison.csv', index=False)\n",
    "print(\"\\nüíæ Saved: method_summary.csv, performance_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. CellBender Reference (Command-line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã CellBender Usage Reference\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"CellBender must be run via command line (requires GPU):\\n\")\n",
    "\n",
    "cellbender_cmd = \"\"\"\n",
    "# Installation\n",
    "pip install cellbender\n",
    "\n",
    "# Basic usage\n",
    "cellbender remove-background \\\\\n",
    "    --input raw_feature_bc_matrix.h5 \\\\\n",
    "    --output cellbender_output.h5 \\\\\n",
    "    --expected-cells 3000 \\\\\n",
    "    --total-droplets-included 5000 \\\\\n",
    "    --epochs 150 \\\\\n",
    "    --cuda\n",
    "\n",
    "# Load results in Python\n",
    "import scanpy as sc\n",
    "adata = sc.read_10x_h5('cellbender_output_filtered.h5')\n",
    "\"\"\"\n",
    "\n",
    "print(cellbender_cmd)\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è  CellBender is the most sophisticated but requires:\")\n",
    "print(\"   - GPU (CUDA compatible)\")\n",
    "print(\"   - Raw unfiltered matrix\")\n",
    "print(\"   - 30-60 minutes runtime\")\n",
    "print(\"\\n‚úÖ DecontX and FastCAR run in seconds on CPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps & Research Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all corrected datasets\n",
    "print(\"üíæ Exporting results...\\n\")\n",
    "\n",
    "adata_synthetic.write_h5ad('/home/claude/synthetic_raw.h5ad')\n",
    "print(\"‚úÖ Saved: synthetic_raw.h5ad\")\n",
    "\n",
    "adata_decontx.write_h5ad('/home/claude/synthetic_decontx.h5ad')\n",
    "print(\"‚úÖ Saved: synthetic_decontx.h5ad\")\n",
    "\n",
    "adata_fastcar.write_h5ad('/home/claude/synthetic_fastcar.h5ad')\n",
    "print(\"‚úÖ Saved: synthetic_fastcar.h5ad\")\n",
    "\n",
    "adata_pbmc_decontx.write_h5ad('/home/claude/pbmc_decontx.h5ad')\n",
    "print(\"‚úÖ Saved: pbmc_decontx.h5ad\")\n",
    "\n",
    "adata_pbmc_fastcar.write_h5ad('/home/claude/pbmc_fastcar.h5ad')\n",
    "print(\"‚úÖ Saved: pbmc_fastcar.h5ad\")\n",
    "\n",
    "print(\"\\nüéâ All done! Ready for your meeting!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - method_comparison_synthetic.png\")\n",
    "print(\"  - signal_recovery.png\")\n",
    "print(\"  - pbmc_comparison.png\")\n",
    "print(\"  - method_summary.csv\")\n",
    "print(\"  - performance_comparison.csv\")\n",
    "print(\"  - *.h5ad files (all datasets)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
